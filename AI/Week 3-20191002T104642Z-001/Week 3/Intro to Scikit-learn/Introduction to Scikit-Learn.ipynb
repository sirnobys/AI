{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction to Scikit Learn with iris data set\n",
    "\n",
    "The Iris flower dataset was introduced by the British statistician and biologist Ronald Fisher.\n",
    "\n",
    "There are 50 samples of 3 different species of iris (150 samples total)\n",
    "Measurements: sepal length, sepal width, petal length, petal width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iris Flower\n",
    "![iris image](iris.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn more about the Iris Dataset on the UCI page: https://archive.ics.uci.edu/ml/datasets/iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow of Machine Learning with Scikit Learn\n",
    "\n",
    " * Get your dataset (Either you import from Scikit Learn's module or load in your own datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import load_iris function from datasets module\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save \"bunch\" object containing iris dataset and its attributes\n",
    "iris = load_iris()\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* View the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "# print the iris data\n",
    "print(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the shape of data\n",
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# print the names of the four features\n",
    "print(iris.feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# print integers representing the species of each observation\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the shape of target\n",
    "iris.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# check the types of the features and response\n",
    "print(type(iris.data))\n",
    "print(type(iris.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# print the encoding scheme for species: 0 = setosa, 1 = versicolor, 2 = virginica\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-204da8eef4b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "5                  5.4               3.9                1.7               0.4   \n",
       "6                  4.6               3.4                1.4               0.3   \n",
       "7                  5.0               3.4                1.5               0.2   \n",
       "8                  4.4               2.9                1.4               0.2   \n",
       "9                  4.9               3.1                1.5               0.1   \n",
       "10                 5.4               3.7                1.5               0.2   \n",
       "11                 4.8               3.4                1.6               0.2   \n",
       "12                 4.8               3.0                1.4               0.1   \n",
       "13                 4.3               3.0                1.1               0.1   \n",
       "14                 5.8               4.0                1.2               0.2   \n",
       "15                 5.7               4.4                1.5               0.4   \n",
       "16                 5.4               3.9                1.3               0.4   \n",
       "17                 5.1               3.5                1.4               0.3   \n",
       "18                 5.7               3.8                1.7               0.3   \n",
       "19                 5.1               3.8                1.5               0.3   \n",
       "20                 5.4               3.4                1.7               0.2   \n",
       "21                 5.1               3.7                1.5               0.4   \n",
       "22                 4.6               3.6                1.0               0.2   \n",
       "23                 5.1               3.3                1.7               0.5   \n",
       "24                 4.8               3.4                1.9               0.2   \n",
       "25                 5.0               3.0                1.6               0.2   \n",
       "26                 5.0               3.4                1.6               0.4   \n",
       "27                 5.2               3.5                1.5               0.2   \n",
       "28                 5.2               3.4                1.4               0.2   \n",
       "29                 4.7               3.2                1.6               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "120                6.9               3.2                5.7               2.3   \n",
       "121                5.6               2.8                4.9               2.0   \n",
       "122                7.7               2.8                6.7               2.0   \n",
       "123                6.3               2.7                4.9               1.8   \n",
       "124                6.7               3.3                5.7               2.1   \n",
       "125                7.2               3.2                6.0               1.8   \n",
       "126                6.2               2.8                4.8               1.8   \n",
       "127                6.1               3.0                4.9               1.8   \n",
       "128                6.4               2.8                5.6               2.1   \n",
       "129                7.2               3.0                5.8               1.6   \n",
       "130                7.4               2.8                6.1               1.9   \n",
       "131                7.9               3.8                6.4               2.0   \n",
       "132                6.4               2.8                5.6               2.2   \n",
       "133                6.3               2.8                5.1               1.5   \n",
       "134                6.1               2.6                5.6               1.4   \n",
       "135                7.7               3.0                6.1               2.3   \n",
       "136                6.3               3.4                5.6               2.4   \n",
       "137                6.4               3.1                5.5               1.8   \n",
       "138                6.0               3.0                4.8               1.8   \n",
       "139                6.9               3.1                5.4               2.1   \n",
       "140                6.7               3.1                5.6               2.4   \n",
       "141                6.9               3.1                5.1               2.3   \n",
       "142                5.8               2.7                5.1               1.9   \n",
       "143                6.8               3.2                5.9               2.3   \n",
       "144                6.7               3.3                5.7               2.5   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "5         0  \n",
       "6         0  \n",
       "7         0  \n",
       "8         0  \n",
       "9         0  \n",
       "10        0  \n",
       "11        0  \n",
       "12        0  \n",
       "13        0  \n",
       "14        0  \n",
       "15        0  \n",
       "16        0  \n",
       "17        0  \n",
       "18        0  \n",
       "19        0  \n",
       "20        0  \n",
       "21        0  \n",
       "22        0  \n",
       "23        0  \n",
       "24        0  \n",
       "25        0  \n",
       "26        0  \n",
       "27        0  \n",
       "28        0  \n",
       "29        0  \n",
       "..      ...  \n",
       "120       2  \n",
       "121       2  \n",
       "122       2  \n",
       "123       2  \n",
       "124       2  \n",
       "125       2  \n",
       "126       2  \n",
       "127       2  \n",
       "128       2  \n",
       "129       2  \n",
       "130       2  \n",
       "131       2  \n",
       "132       2  \n",
       "133       2  \n",
       "134       2  \n",
       "135       2  \n",
       "136       2  \n",
       "137       2  \n",
       "138       2  \n",
       "139       2  \n",
       "140       2  \n",
       "141       2  \n",
       "142       2  \n",
       "143       2  \n",
       "144       2  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'] = iris.target\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the head of DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the tail of DataFrame\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some key points to note\n",
    "\n",
    "* There are 150 **observations**\n",
    "* There are 4 **features** (sepal length, sepal width, petal length, petal width)\n",
    "* **Response variable/Target** is the iris species (0 = setosa, 1 = versicolor, 2 = virginica).\n",
    "* This is a **Classification problem** since response is categorical/discrete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If your data is clean and in the right state already, you can go on to the next steps, else you need to pre-process the data into a suitable form.\n",
    "\n",
    "    ## Requirements for working with data in scikit-learn\n",
    "\n",
    "    * Features and response are separate objects\n",
    "    * Features and response should be numeric\n",
    "    * Features and response should be NumPy arrays\n",
    "    * Features and response should have specific shapes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store feature matrix in \"X\"\n",
    "X = iris.data\n",
    "\n",
    "# store response vector in \"y\"\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(iris.data))\n",
    "print(type(iris.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "# printing the shape of data\n",
    "print(iris.data.shape)\n",
    "\n",
    "# printing the shape of target\n",
    "print(iris.target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn 4-step modelling pattern\n",
    "\n",
    "Step 1: Import the class of the ML algorithm you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we identify this problem as a classification problem because we want to predict \n",
    "# discrete values, we will use k-nearest neighbor algorithm\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Instantiate the algorithm you want to use.\n",
    "   * You can specify tuning parameters (\"hyperparameters\") during this step\n",
    "   * All parameters not specified are set to their defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Fit the model with the data (\"model training\")\n",
    "   * The algorithm would learn the relationship between X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knn.fit(X,y)\n",
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Predict new observation.\n",
    "* Predict the response for a new observation by using information learned during model training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knn.predict()\n",
    "knn.predict([[3, 5, 4, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict([[5, 4, 3, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can predict for multiple observations\n",
    "X_new = [[3, 5, 4, 2], [5, 4, 3, 2]]\n",
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a different k value and see if we get the same predictions. **k = 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the model (using the value K=5)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# fit the model with data\n",
    "knn.fit(X, y)\n",
    "\n",
    "# predict the response for new observations\n",
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a different classification model **(Logistic Regression)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Students should find out about Logistic Reg.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# predict the response for new observations\n",
    "logreg.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating different ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation procedure #1: Train and test on the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train the model on the entire dataset.\n",
    "* Test the model on the same dataset, and evaluate how well we did by comparing the predicted response values with the true response values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what we have done so far\n",
    "# read in the iris data\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# create X (features) and y (response)\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# predict the response values for the observations in X\n",
    "y_pred = knn.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true y\n",
    "print(y)\n",
    "\n",
    "# predicted y\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# computing classification accuracy for Logistic Regression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN = 5 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X, y)\n",
    "y_pred = knn.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# true y\n",
    "print(y)\n",
    "\n",
    "# predicted y\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification accuracy:\n",
    "\n",
    "* Proportion of correct predictions over total predicted.\n",
    "* Classification accuracy is a common evaluation metric for classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN = 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X, y)\n",
    "y_pred = knn.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# true y\n",
    "print(y)\n",
    "\n",
    "# predicted y\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with training and testing on the same data\n",
    "\n",
    "* Goal is to estimate likely performance of a model on out-of-sample data.\n",
    "* But, training-dataset accuracy won't generalize the model for out-of sample data.\n",
    "* Unnecessarily complex models overfit the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](overfitting.png)\n",
    "Image Credit: [Overfitting](http://commons.wikimedia.org/wiki/File:Overfitting.svg#/media/File:Overfitting.svg) by Chabacano. Licensed under GFDL via Wikimedia Commons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation procedure #2: Train/test split\n",
    "\n",
    "* Split the dataset into two pieces: a **training set** and a **testing set**.\n",
    "* Train the model on the training set.\n",
    "* Test the model on the testing set, and evaluate how well we did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "# print the shapes of X and y\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STEP 1: split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 4)\n",
      "(60, 4)\n"
     ]
    }
   ],
   "source": [
    "# print the shapes of the new X objects\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-1ba284d52ced>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# print the shapes of the new y objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "# print the shapes of the new y objects\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 2: train the model on the training set\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: make predictions on the testing set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# compare actual response values (y_test) with predicted response values (y_pred)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN = 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN = 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.947368421053\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the whole, it looks like KNN is giving us a generally better accuracy than Logistic Regression so let's probe further to see which value for KNN would give us a better score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94736842105263153, 0.94736842105263153, 0.97368421052631582, 0.97368421052631582, 0.97368421052631582, 0.97368421052631582, 0.97368421052631582, 0.97368421052631582, 0.97368421052631582, 0.97368421052631582, 0.97368421052631582, 0.97368421052631582, 0.97368421052631582, 0.97368421052631582, 0.97368421052631582, 0.97368421052631582, 0.97368421052631582, 0.97368421052631582, 0.97368421052631582, 0.94736842105263153, 0.97368421052631582, 0.94736842105263153, 0.97368421052631582, 0.97368421052631582, 0.97368421052631582]\n"
     ]
    }
   ],
   "source": [
    "# try K=1 through K=25 and record testing accuracy\n",
    "k_range = list(range(1, 26))\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    scores.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    \n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# revision of append function\n",
    "num = [1,2,3]\n",
    "num.append(4)\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Testing Accuracy')"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XuYZHV95/H3p7uqu2tmuprbqMhw\nEUMS8bKoE2JiDIjRoDFyMwaSuOi6QbNxN8ZLhDUxCRtivCQmG8km5BGFrIpKorIuWTQIuTxJkCFc\nFAg4i7gMGC4CXXOp6q7Ld/8453QXPVXdp6rOr2rmnO/reeaZ6lPn1Pmd6Tn1Pb/b9yczwznnnBvW\n1KQL4Jxz7uDmgcQ559xIPJA455wbiQcS55xzI/FA4pxzbiQeSJxzzo0kaCCRdLqkeyTtlHRhj/eP\nlXS9pDsk3ShpW7z95ZJu6/rTkHRm/N4nJX27672TQl6Dc8659SnUPBJJ08C9wCuBXcDNwHlmdlfX\nPp8HvmxmV0g6DXizmb1xzeccBuwEtpnZPkmfjI+5OkjBnXPODSRkjeRkYKeZ3Wdmy8BVwBlr9jkR\nuD5+fUOP9wFeD/y1me0LVlLnnHNDKwX87KOAB7p+3gX88Jp9bgfOAf4IOAuYl3S4mX2va59zgT9Y\nc9wlkt5PFIQuNLOltSeXdAFwAcDmzZtf/IM/+IOjXItzzhXOLbfc8piZbd1ov5CBRD22rW1Hezfw\nMUlvAv4OeBBorXyAdCTwfOC6rmMuAv4NmAEuA94LXLzficwui99n+/bttmPHjmGvwznnCknSd9Ls\nFzKQ7AKO7vp5G/BQ9w5m9hBwNoCkLcA5ZrbYtcsbgC+YWbPrmO/GL5ckfYIoGDnnnJuQkH0kNwMn\nSHqWpBmiJqpruneQdISkpAwXAZev+YzzgM+sOebI+G8BZwLfDFB255xzKQULJGbWAt5O1Cx1N/A5\nM7tT0sWSXhfvdipwj6R7gacDlyTHSzqOqEbzt2s++lOSvgF8AzgC+J1Q1+Ccc25jwYb/Hki8j8Q5\n5wYn6RYz277Rfj6z3Tnn3Eg8kDjnnBuJBxLnnHMjCTn816VQazT5i3/6DkvN9qSL4twB75mHVDj3\n5GOCnuN/3f4QP/Z9R3Do5plg57jtgSf52t0PB/v8buf/6HEcvmU26Dk8kEzY1+5+hA9fdw8A6jWF\n0zkHQDIu6FXPfQaHBfqSf2zPEv/5M7fy6z/1HP7jy44Pcg6A3//KPfz9tx4byz3/upOO8kCSd0/u\nWwbg1t94ZdAnIOcOdl+89UHe8dnbWKw3gwWSJ/dFc58X680N9hzNYr3JqT+wlU+++eSg5xkX7yOZ\nsMV6lBFmfs5junPrqVaieyTkl3zy2eMIJNW5ctBzjJMHkgmrNZpsnpmmNO2/CufWk3zx1gJ+ydca\nzeDnSD4/CYx54N9eE1arN1mo5OfJxLlQkvsk+bIPIQkgtUZrgz2HZ2bUGq1c3fceSCZssd6kmqP/\nUM6FktwnIZudamNo2tq73KbdMW/actmpNTyQOJfGSo2kHq62kNREgjafxZ/tNRKXmcV6K1dPJs6F\nMluaYmZ66qDvbE8+O08PkB5IJsz7SJxLRxLVSnlMfSReIxmEB5IJy9voDedCqlZKY6ktNJodllph\nsk0kzWd5aonwQDJB7Y6xe8mbtpxLqzpXHsvwXwjXF7PatJWfB0gPJBO0J34yyVMV17mQFirloENz\nu4NHqOYtb9pymcpjp5tzIVUrYWski119lqGa0JLPnc9RS4QHkglKnnjy9GTiXEgLlVLwpq2jD6tE\nrwOdp9ZoMj9bYnoqP1laPZBM0EqNxPNsOZdKda7MYr1JiCXCOx2jVm+y7ZBNQNgaSd5aITyQTNBK\nW+mmfP2nci6UhUqZVseoB1i/Z+9yi46xWiMJ1BdTq7c8kLjsJE1bPmrLuXRCpklJPvPow6IaScim\nrby1QnggmSDvbHduMKsZgLOvLSSfuXXLLDOlqXCBxJu2XJZq9RbTU2LzzPSki+LcQSFkBuDuwS8L\nAWfQ5zGbhQeSCYoWtykhX2PXuVRWFrfaF65pq1opU50LN4M+b4tagQeSiao18vdk4lxIQWsk9TU1\nkgDNZ612h73L7dzd9x5IJiiPwwCdCyl5kg/Z2V6dK1OtlIOcYyXPVo7So4AHkonKY1upcyHNx6Od\ngnS2x1/yW+ZKUU6vwLWePPFAMkG1hidsdG4QpekptsyWgn3Jz89FM84XAqViyeuQfw8kE7ToKeSd\nG1iojvBaVyd4tVKi1mhlPoM+r0P+gwYSSadLukfSTkkX9nj/WEnXS7pD0o2StsXbXy7ptq4/DUln\nxu89S9JNkr4l6bOSZkJeQ0h5HE/uXGihEjd2D35ZqJRpd4y9y9nOoE+a5LxpKyVJ08ClwKuBE4Hz\nJJ24ZrePAFea2QuAi4EPAJjZDWZ2kpmdBJwG7AO+Eh/zQeCjZnYC8ATwllDXEFKj2Wap1cldFde5\n0EJ1hHe3EITq1M/jWiQQtkZyMrDTzO4zs2XgKuCMNfucCFwfv76hx/sArwf+2sz2KZpwcRpwdfze\nFcCZmZd8DDzzr3PDCbUmSa3eekqNJNqWbSDJ630fMpAcBTzQ9fOueFu324Fz4tdnAfOSDl+zz7nA\nZ+LXhwNPmlnyv6jXZwIg6QJJOyTtePTRR4e8hHBqOW0rdS60UKskLj6ljyRMjaRWb1KaEpVyvrJZ\nhAwkvaZrr+25ejdwiqRbgVOAB4GVRw1JRwLPB64b4DOjjWaXmdl2M9u+devWQcse3GI9Wbc5X1Vc\n50KrBlqTpNZY7bNczemVfdNWtVLOXTaLkN9iu4Cju37eBjzUvYOZPQScDSBpC3COmS127fIG4Atm\nlvw2HwMOkVSKayX7febBIq9VXOdCW6iU2b3Uot2xzBaHarY77Ouacb46gz7bJrRao5XLez5kjeRm\n4IR4lNUMURPVNd07SDpCUlKGi4DL13zGeaw2a2HRWLwbiPpNAM4HvhSg7MF505Zzw0lqC7sznEuy\ncj/GLQQrOb1C1Ehy2AoRLJDENYa3EzVL3Q18zszulHSxpNfFu50K3CPpXuDpwCXJ8ZKOI6rR/O2a\nj34v8E5JO4n6TD4e6hpCyusMV+dCW+0Iz662kNQ8kkXm5gM1beV1yH/Q0Ghm1wLXrtn2/q7XV7M6\nAmvtsffToyPdzO4jGhF2UOvO6+OcSy9ER/ja+3F6SszPZj/xsVZvctShlUw/80DgM9snpNZoUSlP\nM1PyX4FzgwiRAbhXC0E1wJokec347d9iE7K4z9OjODeMEP0XvVKXZD2D3syi9dpz2ArhgWRConWb\n8/cfyrnQQgzN7ZVMsTpXyrQfptHssNzu5PIB0gPJhOS1iutcaGGatvbPgZX1crt5HvLvgWRCfFEr\n54azaWaa6Sll3rRVnhZz5dWvxKxzeuV5gI0HkgnpzuvjnEtPUuZL4SYtBN0zzrNekyTPQ/49kExI\nXicmOTcOWa9J0p1na/UcZfYut2m2O5mcY6UfxgOJy0KnY+z2PhLnhpZ5/0WPpuaFuFN8d0ZpUha9\nRuKytGe5Rcfy+WTi3Dhk3X/RK5BkPfGxluNErR5IJqCW404358Yh61TytUZrvy/4rIcZ53WZXfBA\nMhErTyY5/A/l3DhUM17cqlbfv6k5ybuVVRNard5k08w05en8fe3m74oOAnldbtO5calWsutsN7Oe\nw/GzXm63V4d+XnggmYA8T0xybhwWKmWWWx0azfbIn1Vvtml1bP8aScZZhvM8CdkDyQTkeWKSc+OQ\nZf9Fv/sx65xetXort60QHkgmYGVi0iYPJM4NI8s0Kat9lk/9kq+UpylNKbM+ksUe/TB54YFkAmqN\nFhJsmcnn04lzoa0OzR292alfU/PqDPqMaiQ5TtTqgWQCavUm87MlpjJab9q5okmG6mbStLWvf1Nz\nlvNV8pxfzwPJBNTqTW/Wcm4EmTZtrTP4Jathxp2OsWep5YHEZSfPwwCdG4csZ52vN1Ewq5xeu5da\nmOVzVjt4IJmIPA8DdG4cshy1tV7qkoVKmd2ZnCPfQ/49kEyA10icG81MaYpKeTqzGsnmmWlKPWac\nZ9VHkuf0KOCBZCJ8LRLnRpfVmiS1Rv9O8OpclGXYzEY7h9dIXNai/7j5bCt1blyqlVJG80j6NzUv\nVMo020ajOdqaJL3WhM8TDyRj1mx32Lfczu1/KOfGpTqXXbNTv/sxq9ntec+vt2EgkfQ2SQvjKEwR\n+Kx257KR1eJWtUb/YblZDTNOmuCK3LR1HPAvkj4t6ScClyf3PM+Wc9nIqiM8WtSqd00hqwzAtUaT\nKcHmnGaz2DCQmNmFwAnAp4C3SfqWpIslHRe4bLmUTG7K65OJc+OSWWf7Bn0kyT6jSGa15zWbRao+\nEjPrAPfHfzrAkcCXJH0gWMlyKu9tpc6NS3Uu6mzvdIYfUdXuGLuXWuv0kWRUI8n5kP80fST/SdLX\ngT8CbgFeYGa/CLwQ+NkNjj1d0j2Sdkq6sMf7x0q6XtIdkm6UtK3rvWMkfUXS3ZLuSmpAkj4p6duS\nbov/nDTQFU+YL7PrXDaqlTJmsGd5+FrJ7sb68zuyyum1uE7zWR6kubJtwLlmdl/3RjPrSHpdv4Mk\nTQOXAq8EdgE3S7rGzO7q2u0jwJVmdoWk04APAG+M37sSuMTMvippC1FNKPEeM7s6RdkPOL6olXPZ\nqHY1Ow37YLZRJ/jKOUbMt1Vr5HvuWJqmrS8AjyQ/SJqXtB3AzL65znEnAzvN7D4zWwauAs5Ys8+J\nwPXx6xuS9yWdCJTM7KvxefaY2b4UZT3g5X2Gq3PjkkVH+Orgl97P1OXpKTbNjD6DPu/ZLNIEksuA\n7i/xvcCfpTjuKOCBrp93xdu63Q6cE78+C5iXdDjw/cCTkv5K0q2SPhzXcBKXxM1hH5U02+vkki6Q\ntEPSjkcffTRFccejVm8xU5pirjy98c7Oub6yWAo3TQtBFmuSrNehnwdpAslU3NkOrHS8p/kX6TU8\nYW2v2LuBUyTdCpwCPAi0iJrcXha//0PA8cCb4mMuAn4w3n4Y8N5eJzezy8xsu5lt37p1a4rijkfe\nn0ycG5csJgumaSHIYuLjemlY8iBNIPm2pF+SNC1pStIvE43e2sgu4Oiun7cBD3XvYGYPmdnZZvZC\n4H3xtsX42FvjZrEW8EXgRfH737XIEvAJoia0g0aU+Te/nW7OjUsWkwXT5MAadeLjUqtNo9kpfI3k\nrcArgIfjP6cAv5jiuJuBEyQ9S9IMcC5wTfcOko6QlJThIuDyrmMPlZRUJU4D7oqPOTL+W8CZwHr9\nNAecWo5XSXNunKoZzPFIVSOplEZa0ne9NPV5seGVmdnDwOsH/WAza0l6O3AdMA1cbmZ3SroY2GFm\n1wCnAh+QZMDfAb8cH9uW9G7g+jhg3AL8efzRn4oDjIDbgLcNWrZJqtWbHLJpZtLFcO6gt2WmhDRa\nIKk1mkxPic0z/fssq3Nl7q7vHvocRRhgs2EgiTuz3wQ8F5hLtpvZBRsda2bXAteu2fb+rtdXAz2H\n8cYjtl7QY/tpG533QFZrtDj28M2TLoZzB72pKcVp3kerLVTnSkTPq71VR2zaqm0wVyUP0jRtXUmU\nb+u1wE3As4FGwDLlWt4nJjk3TlGz02hNWxt9wVcrZXY3WrSHnEFfhEnIaQLJ95vZRcAeM/s4cDrw\nvLDFyiczy/0wQOfGadShuWmWvU7e3zNkzWcxRYf+wS5NIEl+S09Keg4wDxwbrkj5tW+5TatjuX4y\ncW6cRh2am2Y4ftJJPux5kqa3PLdEpAkkH5d0KPCbRB3n9wK/H7RUOeXpUZzL1qhDc9dLIZ+ojjjM\nuAhNW+v+C8azyR8zsyeIUpgcM5ZS5dTKMEAPJM5lYvQaycY5sJL3h66R1JvM5jybxbo1EjNrA+8Y\nU1lyzxe1ci5b1Upp5BQpGzdtjTZfJU2H/sEuTdPWdZLeIelISdXkT/CS5VCaWbTOufQWKmXqzTbL\nrc7GO6/RiI/b6Es+WRZ76KatFB36B7s0vT9vjf9+V9c2w5u5BuaLWjmXre7+iyO29Mzf2lct5UTB\nkTvb47kqeZZmZvvRG+3j0vHOduey1b0U7sCBJOX9uGW2xJSGzzK8WG9yxJZ8Z7NIM7P953ptN7NP\nZ1+cfEueaOa9j8S5TIyyJslGa5EkJFGtDN+pX2s0OX5rvrNZpKlvvazr9RxRAsVbAA8kA6rVW8zP\nlpie6p+OwTmX3igrGA4yijJKxTJ8Z3veWyHSNG39UvfP8ZyST4YqUJ7lfU0C58YtWZJhmBFVgzQ1\nDzuDPslmkfeRmmlGba21m2gFQzegxXqT+Zx3ujk3Ttk0baWokQyZ02vvcpuO5X+ATZo+ki+wurLh\nFFEW4C+FLFReeZ4t57I1yqzz2gCjKBcqZR6uLQ18jiLk2YJ0fSQf63rdAr5jZveHKU6+LdabHH3Y\npkkXw7ncmCtPM1OaGrpGMleeYra08YzzYWfQFyE9CqQLJN8CHjGzBoCkiqSjzeyBsEXLn92NjdMx\nOOcGE/VfDNfZnvZ+HLaPpCg1kjR9JH8FdE8b7QB/GaY4+ZYm06hzbjDVudLQX/Jp78dqpcxSq0Oj\n2R7oHGknPR7s0gSSkpktJz+Y2RIw2MwfR6vdYc9SK/edbs6N27ArGA4yijKZazLoeYqSXy9NIPme\npNckP0h6LfB4uCLl056lqOqd9yquc+M2bLPTIDmwVjr1B2xCS+a35P2+T/N4/EvApyVdSjR66zHg\nF4KWKoeK8mTi3LhV58rc/9jegY9brDf5vq1b0p1jyFTySYDbkvNh/2kmJN4LbJd0SPzzk8FLlUPJ\nk0zen0ycG7docavwne0wXNPW/Fz+s1ls2LQl6b9JOsTMnjSzJyUdKum3x1G4PFksSKebc+OWTBY0\ns413jnU6NmAfyXBrkqRZ7yQP0vSRvLa7FhKvlvjT4YqUT57517kwFipl2h1j33L6EVV7lluYpb8f\nu7MMD6Iok5DTBJJpSSs5kCXNAfnOiRyAr0XiXBjDpElZ3DdYn+X8kGuS1OrFGKmZJpBcBXxV0vmS\n/j1wHZ75d2BFmeHq3LgNkyYl2Tftl/xceZrZ0tTAfTFFadpK09n+u5LuAH4CEPAhM/vfwUuWM7VG\nk9KU2DSzcToG51x6C0MMzR0khXz3eQZt2ipCCnlIN/wXM/sy8GUAST8s6Y/M7FeClixnFutRx56U\n79Ebzo3bUE1bQ7QQDLO4Va1ejKUjUgUSSc8DzgPOBR7CU6QMbJChhs659IbpCB9m8MvCgDPom+0O\ne5fbhbjv+wYSSccTBY6fA/YAnwXKZvayfse4/qK8PvnvdHNu3JJ+jkFqC8PkwKrOlXh0T/pU8rvj\n/pQi3PfrdbbvBH4SONvMXmJmHyVKI5+apNMl3SNpp6QLe7x/rKTrJd0h6UZJ27reO0bSVyTdLeku\nScfF258l6SZJ35L02e4RZQcyXx3RuTDm54bobK83kWB+Nv2X/KBZhlcy/27K/32/XiD5WaJ0KNdL\n+hNJpxB1tqciaRq4FHg1cCJwnqQT1+z2EeBKM3sBcDHwga73rgQ+bGbPAU4GHom3fxD4qJmdADwB\nvCVtmSapKG2lzo3b9JSYnx1sBcPFepP52RJTA8w4H7SPpEgjNfsGEjP7vJmdQxQEbgIuAp4h6Y8l\nnZbis08GdprZfXH24KuAM9bscyJwffz6huT9OOCUzOyrcVn2mNk+RT3VpwFXx8dcAZyZoiwTt1hv\nFeI/lHOTUB2wtlBrtAZ+sKvOldndaNLppJtBvzrEOP/3/YbzSMxst5ldYWanA0cD/wr8VorPPgro\nXvxqV7yt2+3AOfHrs4B5SYcTrQn/pKS/knSrpA/HNZzDgSfNrLXOZwIg6QJJOyTtePTRR1MUN6xB\nMo065wYzaCr5YWacL1TKdAz2LqcLWEVZ1ArSTUhcYWaPmdmlZvbjKXbvVWdcG8rfDZwi6VbgFOBB\non6YEvCy+P0fAo4H3pTyM5OyXmZm281s+9atW1MUN5xGs81yq1OIGa7OTUJ1bvCmrUFbCAbt1F+Z\nq1KAloiBAsmAdhHVYBLbiIYOrzCzh8zsbDN7IfC+eNtifOytcbNYC/gi8CKiPptDJJX6feaBqFag\nJxPnJmHQyYLDtBAMOvHRayTZuBk4IR5lNUM0lPia7h0kHSEpKcNFwOVdxx4qKalKnAbcZVF6zxuA\n18fbzwe+FPAaMuFrkTgXVnXAQBJNEB6shWDQiY+1RpPytJgrh/yaPTAEu8K4JvF2otxcdwOfM7M7\nJV0s6XXxbqcC90i6F3g6cEl8bJuoWet6Sd8gatL68/iY9wLvlLSTqM/k46GuISue+de5sAZdk6Q2\nxOCXQXN6JelRipDNYsOQLOkJ9u+HWAR2AO8xs/v7HWtm1wLXrtn2/q7XV7M6AmvtsV8FXtBj+31E\nI8IOGsPk9XHOpVedK7NnqUWr3aE0vf7z8XKrQ705+IzzZP/0fSTFSNgI6VKk/DHwMFHGXxE1UW0l\nmrD4CeDlwUqXE6tNW97Z7lwISTPV7kaLQzevP0d52GG5gy5uVWu0mC/Iw2Oab7ZXmdlLun7+E0n/\nbGYvkfRroQqWJ9605VxY3UvhbhhIhuwEn58rIZG6Ca0omX8hZR+JpLPXvE4a/TohCpU3K4voFOQ/\nlXPjNkhH+LCLzE1NiS2zpdQ1kt0Fyq+XJpD8AvCLkh6X9D3gF4E3StoEvCNo6XKi1miyaWaa8gZt\nt8654ST5rNIMzU1qFMPUFgYZZlykGkmaha12EuXL6uVvsy1OPg0z+ck5l95QNZIh7snqXLp8W2ZW\nqEStaUZtHQH8B+C47v3N7IJwxcqXoqzb7NykJPdXmqG5w6SQ7z5PmnM0mh2abSvMA2Sab7cvAf8M\n/APQDlucfPI8W86FNcjiVqMMflmolLn/sX0b7lekWe2QLpBsNrN3BS9Jji3WmzyjOjfpYjiXW5Xy\nNKUppW7ampmeYrY0eJ9l2qat1SHGxWiJSPMv+deSXhW8JDnmNRLnwpKUeincqKl5uBnnac9RtBpJ\nmkDyNuD/SNoTj9x6QtLjoQuWJ4v7itPp5tykRAtPpRi1NUSere5z7Ftu02yvP/OhSItaQbqmrSOC\nlyLHOh1j99Lgi+g45waTNnHjKC0E3X0xh2+Z7btf0WokfQOJpBPM7FvAc/vsckeYIuXL7qUWZp4e\nxbnQ0q5Jslhvcuim9We/9z1H15ok6wWSUUaGHYzW+3a7kGg99Et7vGdAmsWtCq9o/6Gcm5RqpcyD\nT9Y33K9Wb3Ls4ZuHO0eSb2uDNCnJ+/MFeYDse5Vm9pb45Wlm9pQwL8m/FVPyPFvOjcdCynXba40W\nC0P2kaQdZrxYb7K5QNks0lzlTSm3uR58USvnxqM6F/WRROvf9WZmI2WaSFoWNmpCizr0i3PPr9dH\n8jTgSKAi6fmsJmqsApvGULZcSJ6QvEbiXFgLlTLL7Q5LrQ5z5eme++xbbtPu2Oid7RsMAS5Sni1Y\nv4/kp4hSo2wj6idJAslu4DcClys3VvtIitFW6tykdHeE9wskiyP2WabN6VVrFCu/3np9JJ8APiHp\nDWb2uTGWKVe8j8S58ejuv3h6n0wSo96Pc+UpZqanNuyLqdVbPPOQylDnOBil6SN5mqQqgKQ/lfR1\nSa8IXK7cWKw3mRJsnvEaiXMhpaktrKwNNGRtQRLVysbDjBdHmPR4MEoTSC4ws1qcJmUb8EvAh8IW\nKz9q9Sbzc2WmpgZPx+CcS6+aov8iGZY7ypd8dW7jNClFa9pKE0iSIRCvBj5hZrekPM6RDDUszn8o\n5yZltWmrf7PTsMvsdttoBn27Y+wu2H2fJiDcLula4KeJEjhuYTW4uA0UrYrr3KQk2SPWbdrKYDj+\nRoFkz0qtpziBJM033JuBFwM7zWxfvNDVWzY4xsVqBRsG6NykVFNMFkyapEaZcb5QKfPA4/3XJCla\nni1IUSMxszZwPFHfCEAlzXEu4svsOjce5ekpNs1Mb1gj2TJbojTCjPONcnqtrEVSkPQokCIgSPoY\n8HLgF+JNe4E/DVmoPPG1SJwbn43WC6nVR++7WKisP4M+i36Yg02asPyjZvZWoAFgZo8Dw6XOLKBk\nER3nXHgbrWC4WG+OnEixWinT6hj7lnuvPD7qpMeDUZpA0pQ0RdzBLulwYP1VXRwAy60O9Wa7UFVc\n5yapWimtP2qrMXoOrNUMwL0D1uoyux5IkJR8+10K/CWwVdJvA/8AfHAMZTvo+ax258Zr46at0Zua\nNxpm7J3tT/V1ADO7Evh14CPAE8DPmNlVaT5c0umS7pG0U9KFPd4/VtL1ku6QdKOkbV3vtSXdFv+5\npmv7JyV9u+u9k1Je69gVsYrr3CRt1LRVy2DwS3dOr97naDE9JTbP9M73lUfrtbmsTMU2szuBOwf5\nYEnTRLWZVwK7gJslXWNmd3Xt9hHgSjO7QtJpwAeAN8bv1c2sX5B4j5ldPUh5JsEXtXJuvDaa45HF\nBOGN1iSJZrWXkIqTzWK9QLJV0jv7vWlmf7DBZ59MNPfkPgBJVwFnAN2B5ETgV+PXNwBf3LDEBxFf\ni8S58apWyuxeatHp2H5piVrtDnuWWiNPEN4op9diwdYigfWbtqaBLcB8nz8bOQp4oOvnXfG2brcD\n58SvzwLm4858gDlJOyT9s6Qz1xx3Sdwc9lFJ/RdOnrAkr0+R2kqdm6SFShkz2L20f//F7mTG+chN\nWxt0thdwEvJ6ofm7ZnbxCJ/dq163duD1u4GPSXoT8HfAg0DyP+AYM3tI0vHA1yR9w8z+L3AR8G9E\nQ5AvA94L7FdOSRcAFwAcc8wxI1zG8HwtEufGKxkh2evLPKtO8I1SsRRxEvJ6NZJRG/h2AUd3/bwN\neKh7BzN7yMzONrMXAu+Lty0m78V/3wfcCLww/vm7FlkCPkHUhLYfM7vMzLab2fatW7eOeCnD8aYt\n58ZrvaVwsxqWW5qeYvPMdN9RW7XG6M1nB5v1Asmoa47cDJwg6VmSZoBzgWu6d5B0RDxHBaKaxuXx\n9kOTJqs4t9dLiftWJB0Z/y3gTOCbI5YzmFqjyWxpqu9qbc65bK23FG6Wy16vN8y4aMvswvorJD4+\nygebWUvS24HriPpbLjezOyXlipr/AAAPNklEQVRdDOwws2uAU4EPSDKipq1fjg9/DvBnkjpEwe73\nukZ7fUrSVqIa023A20YpZ0i1Ana6OTdJK5MFe9RIFjNsaq5W+g8zzmKI8cEmaP3LzK4Frl2z7f1d\nr68G9hvGa2b/CDy/z2eelnExg8kir49zLr2FTf0nC2Y5QbjfMONGs81Sq1O4B0jP4htQ1OlWrLZS\n5yZpvY7wLPss+018LGJ6FPBAElQWeX2cc+ltnikxpX59JE2mp8SmDGacVyulleHETz1HMsS4WA+Q\nHkgCKuJ4cucmaWpKfZudkiUdsphxvtDnHEXMswUeSIIq4nhy5yatX7PTYr2VWU2hOhfNoG93njo1\nzpu2XKbMLJO8Ps65wURDc3s1O2XXQpB8zu41TWhFXNQKPJAEs3e5TbtjhZuY5NykVSu9l8LNMgdW\nv4mPtYJOQvZAEkhRn0ycm7R+/RdZDn7ptyZJUhMq2gOkB5JAPD2Kc5PRd2huhn2W/YYZL9abzJWn\nmC0VK5uFB5JAfC0S5yaj2iN9iZlRq2eXA6tfBuAizmoHDyTBeAp55yZjoVKm0eyw1GqvbFtqdVhu\ndzLvbF/bhFbEPFvggSQYb9pybjJWU8mv9l9kfT/27Wwv6CRkDySBeGe7c5PRq9kp6/tx88w001Pq\n0bRVzCH/HkgCSZ5UthQsVYJzk9artrCYcZ+lJKpz+w8zLmp+PQ8kgdQaTebnSkxPjZ6OwTmXXq/+\niywz/3afZ//hv95H4jJUq7e8f8S5CUjuu541kgxrC2vXJOl0rLBrEHkgCSTLWbTOufSSIb7daVJW\nsvJmeE9W5546zHjvcouOFXOAjQeSQKIqbvHaSp2btF6rJIZIXbJ2Bn1RM/+CB5JgijoxyblJmytP\nM1ua2u9LvlKeZqaU3VdelNOrV62neA+QHkgC8bVInJuchTWz20N0gq+dQV/UFPLggSQY7yNxbnLW\ndoRH92O2NYXqXJnlVodGs71yjmR70XggCaDV7rB3ue01EucmZO3Q3BATBdcOMy7yJGQPJAEkazkX\ncWKScweCtZMFQ6xWunbiY9aTHg8mHkgCKPJ/KOcOBL36L7K+H1dyesXnqTVaSDA/W7wHSA8kAYSY\nReucS2/t0NwQg1/WLm5VqzeZny0xVcBsFsULnWPgNRLnJiuaLNjCzDCD3UutzJua1zZtFXVWO3gg\nCSJ5QvEaiXOTsVAp0+4Ye5fbtDtRMMn6S36lRrLStFXcIf8eSAIo8jBA5w4EyVDfxXqTTsfibdne\nj/PJcrv7Vjvbi3rPex9JAKsTkzxOOzcJ3WlSQj3YzZammStPrdZIMlzK92BTzKsOrFZvUp4WlfL0\npIviXCF1z/Fomz1lW9bnSZqyi7rMLgSukUg6XdI9knZKurDH+8dKul7SHZJulLSt6722pNviP9d0\nbX+WpJskfUvSZyXNhLyGYSRVXKl4ozecOxB0d4SvJGwMUFuozq3OoK81vGkrc5KmgUuBVwMnAudJ\nOnHNbh8BrjSzFwAXAx/oeq9uZifFf17Xtf2DwEfN7ATgCeAtoa5hWLVGMZfbdO5AsdoR3go6+CXJ\n6dVsd9hX4GwWIWskJwM7zew+M1sGrgLOWLPPicD18esberz/FIoe8U8Dro43XQGcmVmJM7JYbzJf\n0P9Qzh0Iuhe3CjkcP8npVSv4kP+QgeQo4IGun3fF27rdDpwTvz4LmJd0ePzznKQdkv5ZUhIsDgee\nNLMkiU6vzwRA0gXx8TseffTRUa9lIJ7517nJmp8rIUX3Yq3RZEqwZSb7pq2kRpIsolXU+z5kIOnV\nQWBrfn43cIqkW4FTgAeBJEgcY2bbgZ8D/lDSs1N+ZrTR7DIz225m27du3TrUBQwrWovExzE4NylT\nU2LLbGmlRjI/Vw4y47w6V2JxX3etp5j3fcir3gUc3fXzNuCh7h3M7CHgbABJW4BzzGyx6z3M7D5J\nNwIvBP4SOERSKa6V7PeZB4IQeX2cc4NJlsLtdCzYF3y1Umb3Uosn9y2vnLOIQtZIbgZOiEdZzQDn\nAtd07yDpCElJGS4CLo+3HyppNtkHeClwl5kZUV/K6+Njzge+FPAaBmZmQVJWO+cGkwzNDTn4ZaFS\nxgy+u9hY+bmIggWSuMbwduA64G7gc2Z2p6SLJSWjsE4F7pF0L/B04JJ4+3OAHZJuJwocv2dmd8Xv\nvRd4p6SdRH0mHw91DcNoNDsstzuFfTJx7kBRrZRWJiSGuh+Tz33g8X3xOYt53wdt0DOza4Fr12x7\nf9frq1kdgdW9zz8Cz+/zmfcRjQg7IHnmX+cODAuVMt/53j7aHeP7nrYlyDmSwPHAE/WVcxZRMXuG\nAip6p5tzB4pksmC7Y+FqJPF9/sDj+5iZnmK2VMysU/5tl7EiL7fp3IEkWZOkbcbCpnB9JAC7nthH\ntVLcbBbFDJ8BeeZf5w4M1UqZvcttGs1OsOH4yX3+2J7lQrdCeCDJ2GrmXw8kzk1Sd/AIdT92f26R\nHx49kGTMF7Vy7sDQ3ZwV6n6cn41m0Ic8x8HAA0nGkqateZ/Z7txEddcQQtUWpqbE/Gx0rxe5FcID\nScZq9SabZ6YpT/s/rXOT1F1DCPkln9R8FryPxGVlse7pUZw7EHTfhyG/5JPajveRuMzUGp7517kD\nwdhqJJXyU/4uIg8kGavVW4V+MnHuQDGOPpLuzy5yS4QHkoxFTVvFbSt17kAxV56iPC1mSlPMlaeD\nnSe534v8AOmBJGOeQt65A4MkFirl4E1O3rTlKVIyFzLTqHNuMNW5MqGzlqw2bRX367S4V57C+77w\nDb7+7ccHOmZ3o+U1EucOEFH+q7DnSIb/FvkB0gPJOp55SIUTnj5Y+ukfeMY8P/X8IwOVyDk3iLed\n8uzggeRVJz6DR2pLHHPYprAnOoApWnQw37Zv3247duyYdDGcc+6gIukWM9u+0X7e2e6cc24kHkic\nc86NxAOJc865kXggcc45NxIPJM4550bigcQ559xIPJA455wbiQcS55xzIynEhERJjwLfAY4AHptw\ncSapyNdf5GuHYl+/X/vwjjWzrRvtVIhAkpC0I80szbwq8vUX+dqh2Nfv1x7+2r1pyznn3Eg8kDjn\nnBtJ0QLJZZMuwIQV+fqLfO1Q7Ov3aw+sUH0kzjnnsle0GolzzrmMeSBxzjk3ksIEEkmnS7pH0k5J\nF066POMk6X5J35B0m6Tcr/Al6XJJj0j6Zte2wyR9VdK34r8PnWQZQ+lz7b8l6cH493+bpNdMsoyh\nSDpa0g2S7pZ0p6RfibcX5Xff7/qD//4L0UciaRq4F3glsAu4GTjPzO6aaMHGRNL9wHYzK8SkLEk/\nDuwBrjSz58XbPgQ8bma/Fz9IHGpm751kOUPoc+2/Bewxs49MsmyhSToSONLM/kXSPHALcCbwJorx\nu+93/W8g8O+/KDWSk4GdZnafmS0DVwFnTLhMLhAz+zvg8TWbzwCuiF9fQXSD5U6fay8EM/uumf1L\n/Ho3cDdwFMX53fe7/uCKEkiOAh7o+nkXY/oHPkAY8BVJt0i6YNKFmZCnm9l3IbrhgKdNuDzj9nZJ\nd8RNX7ls2ukm6TjghcBNFPB3v+b6IfDvvyiBRD225b9Nb9VLzexFwKuBX46bP1xx/A/g2cBJwHeB\n359sccKStAX4S+AdZlabdHnGrcf1B//9FyWQ7AKO7vp5G/DQhMoydmb2UPz3I8AXiJr6iubhuA05\naUt+ZMLlGRsze9jM2mbWAf6cHP/+JZWJvkQ/ZWZ/FW8uzO++1/WP4/dflEByM3CCpGdJmgHOBa6Z\ncJnGQtLmuOMNSZuBVwHfXP+oXLoGOD9+fT7wpQmWZaySL9HYWeT09y9JwMeBu83sD7reKsTvvt/1\nj+P3X4hRWwDxkLc/BKaBy83skgkXaSwkHU9UCwEoAZ/O+7VL+gxwKlEK7YeB3wS+CHwOOAb4f8DP\nmFnuOqX7XPupRM0aBtwPvDXpM8gTST8G/D3wDaATb/6vRP0ERfjd97v+8wj8+y9MIHHOORdGUZq2\nnHPOBeKBxDnn3Eg8kDjnnBuJBxLnnHMj8UDinHNuJB5IXC5IulHST67Z9g5Jf7LBcXsCl2urpJsk\n3SrpZWveu1HS9vj1cXF22p/s8RkfjrO5fnjIMpwq6ctdP/+OpOskzcZl2NH13nZJN3YdZ5J+uuv9\nL0s6dZhyuPzyQOLy4jNEE027nRtvn6RXAP9qZi80s7/vtYOkbcB1wLvM7Loeu7wVeJGZvSfNCSWV\n1nnvfcBLgTPNbCne/DRJr+5zyC7gfWnO64rLA4nLi6uB10qahZWkdc8E/kHSFknXS/qXeF2W/TI/\n93hq/5ikN8WvXyzpb+Okl9etmSmc7H9sfI474r+PkXQS8CHgNfE6EJUe5X4G8BXg181sv2wLkq4B\nNgM3SfrZXueJ9/ukpD+QdAPwwV7/QJLeBbwG+Gkzq3e99WHg13sdA9wOLEp6ZZ/3nfNA4vLBzL4H\nfB04Pd50LvBZi2bcNoCz4sSVLwd+P04nsaE4d9EfA683sxcDlwO9MgN8jGgNkBcAnwL+u5ndBrw/\nLsdJa768E1cCHzOzz/e5rtcB9fj4z/Y6T9fu3w/8hJm9q8dHvRR4G/BqM1vbnPdPwJKkl/cqA/A7\n9A80znkgcbnS3bzV3awl4Hcl3QH8DdESAk9P+Zk/ADwP+Kqk24i+ULf12O9HgE/Hr/8C+LGUn/83\nwBslbUq5/3rn+byZtfsct5Po3+FVfd7vGyySJrm1fTzOJTyQuDz5IvAKSS8CKskiP8DPA1uBF5vZ\nSUQ5qObWHNviqfdD8r6AO+MawUlm9nwz6/dl3C1t7qEPEeWC+vx6fRspz7N3nf0eJmrW+mivmoeZ\nfY3oml/S5/hL8L4S14cHEpcbcZPNjUTNT92d7AvAI2bWjL9Ej+1x+HeAE+ORTAtEneQA9wBbJf0I\nRE1dkp7b4/h/ZLU29PPAPwxQ9F8FasDHUzS5DX0eM7sXOBv4n3H/zVqXAL/W59ivAIcC/y7t+Vxx\neCBxefMZoi+7q7q2fQrYHg9z/XngX9ceZGYPEGWIvSPe/9Z4+zLweuCDkm4HbgN+tMd5/wvw5rj5\n7I3Ar6QtcNyPcz5wJFENZT1Dnyc+183Am4FrJD17zXvXAo+uc/gl9G7WcwXn2X+dc86NxGskzjnn\nRuKBxDnn3Eg8kDjnnBuJBxLnnHMj8UDinHNuJB5InHPOjcQDiXPOuZH8f8p0HcLDttEYAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d9b287cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import Matplotlib (scientific plotting library)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# allow plots to appear within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# plot the relationship between K and testing accuracy\n",
    "plt.plot(k_range, scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Testing Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the model with the best known parameters\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "\n",
    "# train the model with X and y (not X_train and y_train)\n",
    "knn.fit(X, y)\n",
    "\n",
    "# make a prediction for an out-of-sample observation\n",
    "knn.predict([[3, 5, 4, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An even better model with Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing accuracy is a better estimate than training accuracy of out-of-sample performance but, it would be better to use cross validation since changing which observations happen to be in the testing set can significantly change testing accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the iris data\n",
    "iris = load_iris()\n",
    "\n",
    "# create X (features) and y (response)\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We'll first use train-test-split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use train/test split with different random_state values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=4)\n",
    "\n",
    "# check classification accuracy of KNN with K=11\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps for K-fold cross-validation\n",
    "\n",
    "* Split the dataset into K equal partitions (or \"folds\").\n",
    "* Use fold 1 as the testing set and the union of the other folds as the training set.\n",
    "* Calculate testing accuracy.\n",
    "* Repeat steps 2 and 3 K times, using a different fold as the testing set each time.\n",
    "* Use the average testing accuracy as the estimate of out-of-sample accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](cross.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          0.93333333  1.          1.          1.          0.86666667\n",
      "  0.93333333  0.93333333  1.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with K=11 for KNN (the n_neighbors parameter)\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966666666667\n"
     ]
    }
   ],
   "source": [
    "# use average accuracy as an estimate of out-of-sample accuracy\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95999999999999996, 0.95333333333333337, 0.96666666666666656, 0.96666666666666656, 0.96666666666666679, 0.96666666666666679, 0.96666666666666679, 0.96666666666666679, 0.97333333333333338, 0.96666666666666679, 0.96666666666666679, 0.97333333333333338, 0.98000000000000009, 0.97333333333333338, 0.97333333333333338, 0.97333333333333338, 0.97333333333333338, 0.98000000000000009, 0.97333333333333338, 0.98000000000000009, 0.96666666666666656, 0.96666666666666656, 0.97333333333333338, 0.95999999999999996, 0.96666666666666656, 0.95999999999999996, 0.96666666666666656, 0.95333333333333337, 0.95333333333333337, 0.95333333333333337]\n"
     ]
    }
   ],
   "source": [
    "# search for an optimal value of K for KNN using cross-vsl-score\n",
    "k_range = list(range(1, 31))\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "    k_scores.append(scores.mean())\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Cross-Validated Accuracy')"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8d9b17e4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with the best KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "print(cross_val_score(knn, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953333333333\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "print(cross_val_score(logreg, X, y, cv=10, scoring='accuracy').mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, we would choose the k = 20 model with cross validation as our ideal model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "References: \n",
    "* https://en.wikipedia.org/wiki/Iris_flower_data_set \n",
    "* https://github.com/justmarkham/scikit-learn-videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
