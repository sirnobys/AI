{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(338, 338, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('../imgs/butterfly.jpg')\n",
    "img.shape # this shows number of rows, columns and channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342732"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#returns total number of pixels in image\n",
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([153, 194, 203], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px = img[100,100]\n",
    "px # returns BGR value at that specific pixel location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing only blue pixel at specific location\n",
    "blue_pix = img[100,100,0]\n",
    "blue_pix\n",
    "\n",
    "b,g,r = cv2.split(px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a better way of accesssing blue value\n",
    "img.item(100,100,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([255, 255, 255], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modifying pixels by assignment\n",
    "img[100,100] = [255,255,255]\n",
    "img[100,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a better way to modifying blue value \n",
    "img.itemset((10,10,0),100) \n",
    "img.item(10,10,0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region of Image (ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.imshow('Image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patch = img[180:310, 180:310] \n",
    "img[0:130, 0:130] = patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.imshow('Image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filling patch with white\n",
    "patch.fill(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.imshow('Image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Arithmetic Operations on images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Addition\n",
    "\n",
    "The images to be added must be of the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img1 = cv2.imread('../imgs/butterfly.jpg')\n",
    "img2 = cv2.imread('../imgs/sky.jpeg')\n",
    "\n",
    "img1 = img1[:300,:300]\n",
    "img2 = img2[:300,:300]\n",
    "\n",
    "#result = cv2.add(img1,img2)\n",
    "result = cv2.addWeighted(img1,0.7,img2,0.3,0)\n",
    "\n",
    "\n",
    "cv2.imshow('Added Images',result)\n",
    "cv2.imshow('Sky',img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[151, 187, 211],\n",
       "        [151, 187, 211],\n",
       "        [151, 187, 211],\n",
       "        ..., \n",
       "        [151, 187, 211],\n",
       "        [151, 187, 211],\n",
       "        [151, 187, 211]],\n",
       "\n",
       "       [[151, 187, 211],\n",
       "        [151, 187, 211],\n",
       "        [151, 187, 211],\n",
       "        ..., \n",
       "        [151, 187, 211],\n",
       "        [151, 187, 211],\n",
       "        [151, 187, 211]],\n",
       "\n",
       "       [[151, 187, 211],\n",
       "        [151, 187, 211],\n",
       "        [151, 187, 211],\n",
       "        ..., \n",
       "        [151, 187, 211],\n",
       "        [151, 187, 211],\n",
       "        [151, 187, 211]],\n",
       "\n",
       "       ..., \n",
       "       [[151, 187, 211],\n",
       "        [150, 186, 210],\n",
       "        [150, 186, 210],\n",
       "        ..., \n",
       "        [150, 187, 207],\n",
       "        [149, 189, 208],\n",
       "        [149, 189, 208]],\n",
       "\n",
       "       [[150, 186, 210],\n",
       "        [150, 186, 210],\n",
       "        [150, 186, 210],\n",
       "        ..., \n",
       "        [152, 189, 209],\n",
       "        [150, 190, 209],\n",
       "        [150, 190, 209]],\n",
       "\n",
       "       [[151, 187, 211],\n",
       "        [151, 187, 211],\n",
       "        [150, 186, 210],\n",
       "        ..., \n",
       "        [152, 189, 209],\n",
       "        [150, 190, 209],\n",
       "        [150, 190, 209]]], dtype=uint8)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[235, 231, 203],\n",
       "        [243, 229, 200],\n",
       "        [230, 197, 164],\n",
       "        ..., \n",
       "        [201,  94,  50],\n",
       "        [199,  94,  51],\n",
       "        [199,  94,  51]],\n",
       "\n",
       "       [[251, 240, 213],\n",
       "        [253, 232, 204],\n",
       "        [237, 199, 167],\n",
       "        ..., \n",
       "        [201,  94,  50],\n",
       "        [199,  94,  51],\n",
       "        [199,  94,  51]],\n",
       "\n",
       "       [[255, 236, 211],\n",
       "        [251, 221, 194],\n",
       "        [233, 186, 155],\n",
       "        ..., \n",
       "        [201,  94,  50],\n",
       "        [199,  94,  51],\n",
       "        [199,  94,  51]],\n",
       "\n",
       "       ..., \n",
       "       [[247, 228, 220],\n",
       "        [248, 230, 219],\n",
       "        [249, 230, 222],\n",
       "        ..., \n",
       "        [245, 234, 226],\n",
       "        [244, 235, 226],\n",
       "        [243, 234, 225]],\n",
       "\n",
       "       [[243, 223, 212],\n",
       "        [243, 224, 211],\n",
       "        [245, 225, 214],\n",
       "        ..., \n",
       "        [247, 236, 228],\n",
       "        [245, 235, 228],\n",
       "        [244, 234, 227]],\n",
       "\n",
       "       [[243, 219, 207],\n",
       "        [243, 219, 207],\n",
       "        [244, 220, 208],\n",
       "        ..., \n",
       "        [246, 235, 227],\n",
       "        [246, 234, 228],\n",
       "        [246, 234, 228]]], dtype=uint8)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding\n",
    "\n",
    "Explanation of thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16, 15, 15, ..., 13, 14, 15],\n",
       "       [14, 14, 15, ..., 14, 15, 15],\n",
       "       [13, 14, 15, ..., 14, 14, 14],\n",
       "       ..., \n",
       "       [11, 10, 10, ..., 26, 28, 30],\n",
       "       [12, 11, 11, ..., 28, 29, 29],\n",
       "       [12, 11, 11, ..., 28, 29, 29]], dtype=uint8)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookpage = cv2.imread('../imgs/bookpage.jpg',0)\n",
    "bookpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple binary thresholding\n",
    "bookpage = cv2.imread('../imgs/bookpage.jpg',0)\n",
    "ret, thresh_bin = cv2.threshold(bookpage, 12, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow('Original', bookpage)\n",
    "cv2.imshow('Binary Threshold', thresh_bin)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaptive thresholding - this takes in different patches of the image and applies relative binary thresholding\n",
    "# to different parts of the image.\n",
    "#Takes in img,highest value,adptive threshold value,\n",
    "#kind of threshold used,blocksize of pixel from which mean is calculated,\n",
    "#constant subtracted from adaptive threshold\n",
    "\n",
    "adapt_thresh = cv2.adaptiveThreshold(bookpage, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,85,3)\n",
    "\n",
    "cv2.imshow('Original', bookpage)\n",
    "cv2.imshow('Binary Threshold', thresh_bin)\n",
    "cv2.imshow('Adaptive Threshold', adapt_thresh)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = cv2.imread('../imgs/sky.jpeg')\n",
    "inc = cv2.resize(img3,None,fx=2, fy=2, interpolation = cv2.INTER_CUBIC)\n",
    "dec = cv2.resize(img3,None,fx=0.5, fy=0.5, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "cv2.imshow('Original', img3)\n",
    "cv2.imshow('Resize X 2', inc)\n",
    "cv2.imshow('Resize X 0.5', dec)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../imgs/sky.jpeg',0)\n",
    "rows,cols = img.shape\n",
    "\n",
    "M = np.float32([[1,0,200],[0,1,150]])\n",
    "dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "cv2.imshow('img',dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('../imgs/sky.jpeg',0)\n",
    "rows,cols = img.shape\n",
    "# cols-1 and rows-1 are the coordinate limits/points about which to rotate, then angle, scale\n",
    "M = cv2.getRotationMatrix2D(((cols-1)/2.0,(rows-1)/2.0),-100,1)\n",
    "dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "cv2.imshow('img',dst)\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('../imgs/hillary_clinton.jpg',0)\n",
    "edges = cv2.Canny(img,100,200)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('edges',edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
